{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import statistics\n",
    "from pylab import rcParams\n",
    "from scipy.signal import lfilter, filtfilt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import time\n",
    "\n",
    "rf = pickle.load(open('activityID_rf.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANKING_diabetes = {\n",
    "    '003':20,\n",
    "    '009':21,\n",
    "    '007':22,\n",
    "    '005':23,\n",
    "    '006':24,\n",
    "    '008':26,\n",
    "    '004':27,\n",
    "    '001':28,\n",
    "    '002':29,\n",
    "    \n",
    "}\n",
    "RANKING_healthy = {\n",
    "    '016':1,\n",
    "    '002':2,\n",
    "    '005':3,\n",
    "    '008':4,\n",
    "    '003':5,\n",
    "    '019':6,\n",
    "    '009':7,\n",
    "    '010':8,\n",
    "    '020':9,\n",
    "    '006':10,\n",
    "    '018':11,\n",
    "    '013':12,\n",
    "    '015':13,\n",
    "    '007':14,\n",
    "    '014':15,\n",
    "    '017':16,\n",
    "    '004':17,\n",
    "    '011':18,\n",
    "    '001':19,\n",
    "    '012':25,\n",
    "}\n",
    "RANKING_healthy_num = {\n",
    "    16:1,\n",
    "    2:2,\n",
    "    5:3,\n",
    "    8:4,\n",
    "    3:5,\n",
    "    19:6,\n",
    "    9:7,\n",
    "    10:8,\n",
    "    20:9,\n",
    "    6:10,\n",
    "    18:11,\n",
    "    13:12,\n",
    "    15:13,\n",
    "    7:14,\n",
    "    14:15,\n",
    "    17:16,\n",
    "    4:17,\n",
    "    11:18,\n",
    "    1:19,\n",
    "    12:25,\n",
    "}\n",
    "RANKING_COMPOSE = {\n",
    "    10:1,\n",
    "    13:2,\n",
    "    19:3,\n",
    "    15:4,\n",
    "    18:5,\n",
    "    5:6,\n",
    "    17:7,\n",
    "    2:8,\n",
    "    9:9,\n",
    "    12:10,\n",
    "    16:11,\n",
    "    20:12,\n",
    "    7:13,\n",
    "    8:14,\n",
    "    11:15,\n",
    "    1:16,\n",
    "    14:17,\n",
    "    6:18,\n",
    "    3:19,\n",
    "    4:20\n",
    "    \n",
    "}\n",
    "\n",
    "RANKING_COMPOSE_DOCS = {\n",
    "    5:1,\n",
    "    10:2,\n",
    "    19:3,\n",
    "    15:4,\n",
    "    9:5,\n",
    "    18:6,\n",
    "    8:7,\n",
    "    13:8,\n",
    "    17:9,\n",
    "    2:10,\n",
    "    1:11,\n",
    "    12:12,\n",
    "    16:13,\n",
    "    20:14,\n",
    "    7:15,\n",
    "    6:16,\n",
    "    14:17,\n",
    "    11:18,\n",
    "    3:19,\n",
    "    4:20\n",
    "}\n",
    "\n",
    "\n",
    "WEIGHTED_RANKING_healthy = {\n",
    "    16:1,\n",
    "    2:2,\n",
    "    5:3,\n",
    "    8:4,\n",
    "    3:5,\n",
    "    19:20,\n",
    "    9:21,\n",
    "    10:22,\n",
    "    20:23,\n",
    "    6:23,\n",
    "    18:25,\n",
    "    13:26,\n",
    "    15:27,\n",
    "    7:28,\n",
    "    14:29,\n",
    "    17:30,\n",
    "    4:31,\n",
    "    11:32,\n",
    "    1:33,\n",
    "    12:50,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in overall_data.groupby('ranking', sort=):\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions to load the d1namo dataset, classify activity and extract features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf model\n",
    "#rf = pickle.load(open('activityID_rf.sav', 'rb'))\n",
    "\n",
    "#constants\n",
    "WINDOWSIZE_MINUTES  = 10\n",
    "SEDENTARY_THRESHOLD = 0.02\n",
    "ACTIVE_THRESHOLD    = 0.65\n",
    "SAMPLE_SECONDS      = 6 \n",
    "SAMPLING_RATE       = 100 #Hz\n",
    "SAMPLE_OVERLAP      = 0.5\n",
    "\n",
    "#lists\n",
    "COLUMNS = [\n",
    "    'Time',\n",
    "    'subject_id',\n",
    "    \n",
    "    #activity domain features\n",
    "    'breathing_rate',\n",
    "\n",
    "    's_avg_activity',\n",
    "    's_activityLvl',\n",
    "    \n",
    "\n",
    "    'c_main_activity',\n",
    "    'c_activityLvl',\n",
    "    \n",
    "    #heart health domain features\n",
    "    'heart_rate_max_min',\n",
    "    'heart_rate_max_min_day',\n",
    "    'standard_deviation_HR',\n",
    "    'standard_deviation_HR_day',\n",
    "    'standard_deviation_of_the_interbeat_interval',\n",
    "    'average_resting_heart_rate',\n",
    "    'average_resting_heart_rate_day',\n",
    "    'average_heart_rate_by_s_activity',\n",
    "    'proportion_low_activity_above_resting_HR',\n",
    "    'average_heart_rate_day',\n",
    "    \n",
    "    #diet domain features\n",
    "    'glucose_in_window',\n",
    "    'calories_per_day',\n",
    "    'unbalanced_diet_window',\n",
    "    'bad_quality_diet_window',   \n",
    "]\n",
    "\n",
    "CORE_FEATURES = [\n",
    "        \"x_vert_accel_16g_chest\",\n",
    "        \"y_lat_accel_16g_chest\",\n",
    "        \"z_sagit_accel_16g_chest\",\n",
    "    ]\n",
    "\n",
    "activity_lvls = {\n",
    "        0 : 1,\n",
    "        1 : 0,\n",
    "        2 : 0,\n",
    "        3 : 1,\n",
    "        4 : 1,\n",
    "        5 : 2,\n",
    "        6 : 2,\n",
    "        7 : 2,\n",
    "        9 : 0,\n",
    "        10: 0,\n",
    "        11: 0,\n",
    "        12: 2,\n",
    "        13: 1,\n",
    "        16: 1,\n",
    "        17: 1,\n",
    "        18: 1,\n",
    "        19: 1,\n",
    "        20: 2,\n",
    "        24: 2,\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "#Funtions\n",
    "def extract_features(accel_file_path,summary_file_path, subject_no, diet_params_arr):\n",
    "    summary_file   = pd.read_csv(summary_file_path)\n",
    "    current_day    = pd.to_datetime(summary_file.Time[1][1:10], dayfirst=True).date().strftime(\"%Y-%m-%d\")\n",
    "    start_time     = pd.to_datetime(summary_file.Time[1]).time().strftime(\"%H:%M\")\n",
    "    end_time       = pd.to_datetime(summary_file.Time[len(summary_file)-1]).time().strftime(\"%H:%M\")\n",
    "    accel_features = generate_acceleration_features(accel_file_path)\n",
    "    \n",
    "    summary_file['c_activity_main'] = pd.Series(np.repeat(rf.predict(accel_features), 3))\n",
    "    summary_file['c_activity_main'] = summary_file['c_activity_main'].fillna(0)\n",
    "    summary_file['c_ActivityLvl']   = [activity_lvls[x] for x in summary_file.c_activity_main]\n",
    "    \n",
    "    day_features_temp = pd.DataFrame()\n",
    "    day_features_temp = day_features_temp.append(extract_activity_domain_features(summary_file),\\\n",
    "                                                 ignore_index = True)\n",
    "    day_features_temp = pd.concat([day_features_temp, \\\n",
    "                                   extract_heart_domain_features(summary_file)], axis=1) \n",
    "    day_features_temp = pd.concat([day_features_temp, \\\n",
    "                                   extract_diet_domain_features(\\\n",
    "                                                                diet_params_arr\n",
    "                                                                , current_day\n",
    "                                                                , start_time\n",
    "                                                                , end_time)], axis=1)\n",
    "    \n",
    "    day_features_temp['subject_id'] = subject_no\n",
    "\n",
    "    return day_features_temp\n",
    "\n",
    "\n",
    "def generate_acceleration_features(accel_file_path):\n",
    "    accel_df = pd.read_csv(accel_file_path)\n",
    "    accel_df = accel_df[accel_df.notna()] #remove NAs \n",
    "    \"\"\"\n",
    "    Transforming the data by subtracting 2048 from the sensor readings, dividing by 83 \n",
    "    to get the acceleration in m/sÂ² and then multiplying by the gravity constant to get the acceleration \n",
    "    in g, as in the dataset used for training & testing the activity classifier. To keep the timestamps, the process \n",
    "    comprises two steps\n",
    "    \"\"\"\n",
    "    transformed_accel_df =(((accel_df.iloc[:,1:4]-2048)/83)*9,81)[0]\n",
    "    transformed_accel_df = (transformed_accel_df\n",
    "                              .rename(columns = {\"Vertical\": CORE_FEATURES[0],\n",
    "                                                 \"Lateral\" : CORE_FEATURES[1],\n",
    "                                                 \"Sagittal\": CORE_FEATURES[2]\n",
    "                                                }))\n",
    "    return create_features_from_dataset(transformed_accel_df)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def extract_activity_domain_features( summary_file):\n",
    "    summary_file['s_activityLvl'] = calculate_summary_activity_based_activity_level(summary_file.Activity)\n",
    "    activity_domain_features      = pd.DataFrame()\n",
    "    \n",
    "    window_summary = {}\n",
    "    samples        = window_df(summary_file,WINDOWSIZE_MINUTES*60 , overlap=0)\n",
    "\n",
    "    for idx,sample in enumerate(samples):\n",
    "\n",
    "        counted_c_activities      = Counter(sample.c_ActivityLvl)\n",
    "        counted_s_activities      = Counter(sample.s_activityLvl)\n",
    "        valid_activity            = sample[sample.Activity>0].Activity.mean()\n",
    "        valid_BR                  = sample[(sample.BR>4)&(sample.BR<70)].BR.mean()\n",
    "        window_summary['Time']    = sample.Time.iloc[0]\n",
    "        window_summary['breathing_rate' ]   = valid_BR\n",
    "        window_summary['s_avg_activity' ]   = valid_activity\n",
    "        window_summary['c_activityLvl'  ]   = Counter(sample.c_ActivityLvl).most_common(1)[0][0]\n",
    "        window_summary['c_main_activity']   = (counted_c_activities.most_common(1)[0][0]\\\n",
    "                    if (counted_c_activities.most_common(1)[0][0] !=0)|(len(counted_c_activities)==1) \\\n",
    "                    else counted_c_activities.most_common(2)[1][0]) \n",
    "        window_summary['s_activityLvl'  ]   = counted_s_activities.most_common(1)[0][0]\n",
    "        window_summary['s_breathing_by_act']= valid_BR / valid_activity\n",
    "\n",
    "        activity_domain_features  = activity_domain_features.append(window_summary, ignore_index=True)\n",
    "        \n",
    "    return activity_domain_features\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def extract_heart_domain_features(summary_file): \n",
    "    heart_domain_features  = pd.DataFrame()\n",
    "    valid_summary_file     = summary_file[(summary_file.HR>25) & (summary_file.HR<240)]\n",
    "    \n",
    "    window_summary         = {}\n",
    "    samples                = window_df(summary_file,WINDOWSIZE_MINUTES*60 , overlap=0)\n",
    "    \n",
    "    heart_rate_max_min_day = valid_summary_file.HR.max() - valid_summary_file.HR.min()\n",
    "    heart_rate_std_day     = valid_summary_file.HR.std()\n",
    "    hrv_variability        = calculate_standard_deviation_of_the_interbeat_interval(valid_summary_file.HRV)\n",
    "    average_resting_heart_rate = valid_summary_file[valid_summary_file.Activity<SEDENTARY_THRESHOLD].HR.mean()\n",
    "    average_heart_rate_day = valid_summary_file.HR.mean()\n",
    "    \n",
    "    for idx,sample in enumerate(samples):\n",
    "            sample = sample[(sample.HR>25) & (sample.HR<240)]\n",
    "            if len(sample)>0:\n",
    "                window_summary['heart_rate_max_min']         = sample.HR.max() - sample.HR.min()\n",
    "                window_summary['heart_rate_max_min_day']     = heart_rate_max_min_day\n",
    "                window_summary['sandard_deviation_HR_day']   = heart_rate_std_day\n",
    "                window_summary['standard_deviation_HR']       = sample.HR.std()\n",
    "                window_summary['standard_deviation_of_the_interbeat_interval'] = hrv_variability\n",
    "                window_summary['average_resting_heart_rate']       =sample[sample.Activity<SEDENTARY_THRESHOLD].HR.mean()\n",
    "                window_summary['average_resting_heart_rate_day']   = average_resting_heart_rate\n",
    "                window_summary['average_heart_rate_day']     = average_heart_rate_day\n",
    "                window_summary['proportion_low_activity_above_resting_HR']= len(sample[\\\n",
    "                                                                                       (sample.Activity <= SEDENTARY_THRESHOLD)& \\\n",
    "                                                                                       (sample.HR >= average_resting_heart_rate)\n",
    "                                                                                      ])\\\n",
    "                                                                            /len(sample)\n",
    "            else:\n",
    "                window_summary['heart_rate_max_min']         = -1\n",
    "                window_summary['heart_rate_max_min_day']     = -1\n",
    "                window_summary['sandard_deviation_HR_day']   = -1\n",
    "                window_summary['standard_deviation_HR']       = -1\n",
    "                window_summary['standard_deviation_of_the_interbeat_interval'] = -1\n",
    "                window_summary['average_resting_heart_rate']       = -1\n",
    "                window_summary['average_resting_heart_rate_day']   = -1\n",
    "                window_summary['average_heart_rate_day']     = -1\n",
    "                window_summary['proportion_low_activity_above_resting_HR'] = -1\n",
    "                \n",
    "            heart_domain_features = heart_domain_features.append(window_summary, ignore_index = True) \n",
    "    return heart_domain_features\n",
    "\n",
    "\n",
    "def calculate_standard_deviation_of_the_interbeat_interval(summary_file_HRV):\n",
    "    samples          = window_df(summary_file_HRV,5*60 , overlap=0)\n",
    "    window_summary   = np.array([])\n",
    "    for idx,sample in enumerate(samples):\n",
    "        sample = sample[sample<65535]\n",
    "        window_summary = np.append(window_summary,sample.mean() )\n",
    "        \n",
    "    return window_summary[~np.isnan(window_summary)].mean()\n",
    "\n",
    "\n",
    "def calculate_summary_activity_based_activity_level(summary_file_Activity):\n",
    "    return_array = []\n",
    "    for i in range(len(summary_file_Activity)):\n",
    "        if summary_file_Activity[i]   <= SEDENTARY_THRESHOLD:\n",
    "            return_array.append(0)\n",
    "        elif summary_file_Activity[i] >= ACTIVE_THRESHOLD:\n",
    "             return_array.append(2)\n",
    "        else:\n",
    "             return_array.append(1)\n",
    "    return return_array\n",
    "                                                                     \n",
    "    \n",
    "def extract_diet_domain_features(subject_diet_params,date,start_time,end_time ):\n",
    "    print(f'gluco date: {date}')\n",
    "\n",
    "    glucose, food      = subject_diet_params\n",
    "\n",
    "    glucose_day        = glucose[glucose.date == date].reset_index()\n",
    "    #food_day           = food[(food.date      == date) & (food.calories>0)].reset_index()\n",
    "    starttime          = start_time\n",
    "    endtime = end_time\n",
    "\n",
    "    diary_df           = pd.DataFrame()\n",
    "\n",
    "    n_10_min_windows   = round(((timedelta(hours = (time.strptime(endtime,'%H:%M'))\\\n",
    "                                                 .tm_hour, minutes = time.strptime(endtime,'%H:%M')\\\n",
    "                                                 .tm_min).total_seconds()/60) - \\\n",
    "                               (timedelta(hours = time.strptime(starttime,'%H:%M')\\\n",
    "                                                 .tm_hour, minutes = time.strptime(starttime,'%H:%M')\\\n",
    "                                                 .tm_min).total_seconds()/60))/WINDOWSIZE_MINUTES\n",
    "                            )\n",
    "    if n_10_min_windows < 0:\n",
    "        overhead = (timedelta(hours = (time.strptime(endtime,'%H:%M'))\\\n",
    "                                                     .tm_hour, minutes = time.strptime(endtime,'%H:%M')\\\n",
    "                                                     .tm_min).total_seconds()/60)\n",
    "        endtime = '23:59'\n",
    "        min_diff = ((timedelta(hours = (time.strptime(endtime,'%H:%M'))\\\n",
    "                                                 .tm_hour, minutes = time.strptime(endtime,'%H:%M')\\\n",
    "                                                 .tm_min).total_seconds()/60) - \\\n",
    "                               (timedelta(hours = time.strptime(starttime,'%H:%M')\\\n",
    "                                                 .tm_hour, minutes = time.strptime(starttime,'%H:%M')\\\n",
    "                                                 .tm_min).total_seconds()/60))\n",
    "        n_10_min_windows = round((min_diff+overhead)/WINDOWSIZE_MINUTES)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    glucose_day_time_array = np.append(\\\n",
    "                                        np.array([s.translate(str.maketrans('', '', string.punctuation)) \\\n",
    "                                                  for s in glucose_day.time]).astype(int)\\\n",
    "                                        ,99999)\n",
    "    glucose_time_index  = 0\n",
    "\n",
    "    #food_day_time_array = np.append(\\\n",
    "                                        #np.array([s.translate(str.maketrans('', '', string.punctuation))\\\n",
    "                                         #         for s in food_day.time]).astype(int)\\\n",
    "                                        #,99999)\n",
    "    #food_time_index     = 0\n",
    "    time_index          = int(starttime.translate(str.maketrans('', '', string.punctuation)))\n",
    "    for i in range(1, n_10_min_windows):\n",
    "        PGC_score       = 0 \n",
    "        g1, g2          = glucose_day_time_array[glucose_time_index], glucose_day_time_array[glucose_time_index+1]\n",
    "        #f1,f2           = food_day_time_array[food_time_index],food_day_time_array[food_time_index+1]\n",
    "        if abs(g1 - time_index) > abs(g2 - time_index):\n",
    "            glucose_time_index += 1 \n",
    "        #if abs(f1 - time_index) > abs(f2 - time_index):\n",
    "         #   food_time_index    += 1 \n",
    "        \n",
    "        #calculating a blood plasma glucose concentration score that exponentially punishes abnormal values \n",
    "        #in accordance with the NICE reccomendataions:\n",
    "        #https://www.nice.org.uk/guidance/ng17/ifp/chapter/Testing-your-own-blood-glucose-and-target-levels\n",
    "        if glucose_day.type[glucose_time_index]=='BB':\n",
    "            PGC_score = ((abs(6 - glucose_day.glucose[glucose_time_index])-1)*10)**2 \\\n",
    "            if 6 - glucose_day.glucose[glucose_time_index]>1 \\\n",
    "            else 0\n",
    "        elif glucose_day.type[glucose_time_index].startswith('B'):\n",
    "            PGC_score = ((abs(6 - glucose_day.glucose[glucose_time_index])-1)*10)**2 \\\n",
    "            if 6.5 - glucose_day.glucose[glucose_time_index]>1.5 \\\n",
    "            else 0\n",
    "        else:\n",
    "            PGC_score = ((abs(6 - glucose_day.glucose[glucose_time_index])-1)*10)**2 \\\n",
    "            if 7 - glucose_day.glucose[glucose_time_index]>2 \\\n",
    "            else 0\n",
    "            \n",
    "        \n",
    "        diary_df        = diary_df.append({\n",
    "            'glucose'                : glucose_day.glucose[glucose_time_index],\n",
    "            #'cals'                   : food_day.calories[food_time_index],\n",
    "            #'unbalanced_diet_window' : food_day.calories[food_time_index] if food_day.balance[food_time_index]=='Unbalance' else 0,\n",
    "            #'bad_quality_diet_window': food_day.calories[food_time_index] if food_day.quality[food_time_index]=='Low quality' else 0,\n",
    "            'PGC_score'              : PGC_score\n",
    "        }, ignore_index = True)\n",
    "        time_index += 10\n",
    "        if str(time_index)[-2] == '6':\n",
    "            time_index += 40\n",
    "\n",
    "    print(len(diary_df))\n",
    "    return diary_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_feature_table(path):\n",
    "    os_path            = os.path.join(os.getcwd() + path)                 \n",
    "    extracted_features = pd.DataFrame()\n",
    "    all_subjects       = np.array([name for name in os.listdir(os_path)])\n",
    "\n",
    "    for subject_no in all_subjects:\n",
    "\n",
    "        print('At subject no ', subject_no,' time ',datetime.now().time().strftime(\"%H:%M:%S\") )\n",
    "        \n",
    "        subject_path          = os.path.join(os_path + '/' + subject_no)\n",
    "        day_paths_of_subject  = [os.path.join(subject_path + '/sensor_data/' + folder + '/' + folder) \\\n",
    "                                for folder \\\n",
    "                                in os.listdir(os.path.join(subject_path+'/sensor_data'))]\n",
    "        glucose_record        = pd.read_csv(os.path.join(subject_path  + '/glucose.csv'))\n",
    "        food_record           = pd.read_csv(os.path.join(subject_path  + '/food.csv'))\n",
    "        subject_record        = pd.DataFrame()\n",
    "        for day_path in day_paths_of_subject:\n",
    "            \n",
    "            accel_file_path   = str(day_path) + '_Accel.csv'\n",
    "            summary_file_path = str(day_path) + '_Summary.csv'\n",
    "            \n",
    "            extracted_features_temp = extract_features(accel_file_path,\\\n",
    "                                 summary_file_path,\\\n",
    "                                 subject_no,\\\n",
    "                                 [glucose_record,food_record])\n",
    "            \n",
    "            extracted_features = extracted_features.append(extracted_features_temp, ignore_index = True)\n",
    "            subject_record     = subject_record.append(extracted_features_temp, ignore_index = True)\n",
    "            \n",
    "        subject_record.to_csv(f'summaries_folder/summary_subject_{subject_no}_d.csv')   \n",
    "    #extracted_features['ranking'] = [RANKING_healthy_num[i] for i in extracted_features.subject_id]\n",
    "    return extracted_features\n",
    "\n",
    "\"\"\"added the heart rate std to the core features\"\"\"\n",
    "def create_features_from_dataset(df):\n",
    "  \n",
    "    # 0-center the mean and normalize. this adds about 5 points\n",
    "    df[CORE_FEATURES] = standardize(df[CORE_FEATURES])\n",
    "    \n",
    "    new_group         = defaultdict(list)\n",
    "    \n",
    "    #creating a generator object\n",
    "    samples           = window_df(df, SAMPLE_SECONDS*SAMPLING_RATE, SAMPLE_OVERLAP)\n",
    "\n",
    "\n",
    "    for idx,sample in enumerate(samples):\n",
    "\n",
    "        # means of amplitudes\n",
    "        means = sample[CORE_FEATURES].mean()\n",
    "        new_group['x_accel_mean'].append(means[\"x_vert_accel_16g_chest\"])\n",
    "        new_group['y_accel_mean'].append(means['y_lat_accel_16g_chest'])\n",
    "        new_group['z_accel_mean'].append(means['z_sagit_accel_16g_chest'])\n",
    "\n",
    "        # standard deviation of amplitudes\n",
    "        stds = sample[CORE_FEATURES].std()\n",
    "        new_group['x_accel_std'].append(stds[\"x_vert_accel_16g_chest\"])\n",
    "        new_group['y_accel_std'].append(stds['y_lat_accel_16g_chest'])\n",
    "        new_group['z_accel_std'].append(stds['z_sagit_accel_16g_chest'])\n",
    "        #new_group['heart_std'].append(sample.heart_rate.std()) #added a parameter for heart rate\n",
    "\n",
    "        # max-min\n",
    "        new_group['x_max_min'].append(max(sample.x_vert_accel_16g_chest) - min(sample.x_vert_accel_16g_chest))\n",
    "        new_group['y_max_min'].append(max(sample.y_lat_accel_16g_chest) - min(sample.y_lat_accel_16g_chest))\n",
    "        new_group['z_max_min'].append(max(sample.z_sagit_accel_16g_chest) - min(sample.z_sagit_accel_16g_chest))\n",
    "        #new_group['heart_max_min'].append(max(sample.heart_rate) - min(sample.heart_rate) if\n",
    "          #                                max(sample.heart_rate) - min(sample.heart_rate)>=0 else 0)\n",
    "\n",
    "        # xy, xz, yz correlations\n",
    "        corrs = sample[CORE_FEATURES].corr()\n",
    "        new_group['xy_corr'].append(corrs.loc['x_vert_accel_16g_chest', 'y_lat_accel_16g_chest'])\n",
    "        new_group['xz_corr'].append(corrs.loc['x_vert_accel_16g_chest', 'z_sagit_accel_16g_chest'])\n",
    "        new_group['yz_corr'].append(corrs.loc['y_lat_accel_16g_chest', 'z_sagit_accel_16g_chest'])\n",
    "\n",
    "        # root-mean-square(x, y, z)\n",
    "        rms   = np.sqrt(np.mean(np.square(sample[CORE_FEATURES]), axis=1))\n",
    "        new_group['rms_mean'].append(rms.mean())\n",
    "        new_group['rms_std'].append(rms.std())\n",
    "\n",
    "\n",
    "        # fourier transforms! \n",
    "        x_fft = abs_rfft(sample['x_vert_accel_16g_chest'])\n",
    "        y_fft = abs_rfft(sample['y_lat_accel_16g_chest'])\n",
    "        z_fft = abs_rfft(sample['z_sagit_accel_16g_chest'])\n",
    "\n",
    "        new_group['x_fft_max'].append(x_fft.max())\n",
    "        new_group['y_fft_max'].append(y_fft.max())\n",
    "        new_group['z_fft_max'].append(z_fft.max())\n",
    "\n",
    "        new_group['x_fft_min'].append(x_fft.min())\n",
    "        new_group['y_fft_min'].append(y_fft.min())\n",
    "        new_group['z_fft_min'].append(z_fft.min())\n",
    "\n",
    "        new_group['x_fft_mean'].append(x_fft.mean())\n",
    "        new_group['y_fft_mean'].append(y_fft.mean())\n",
    "        new_group['z_fft_mean'].append(z_fft.mean())\n",
    "\n",
    "        new_group['x_fft_std'].append(x_fft.std())\n",
    "        new_group['y_fft_std'].append(y_fft.std())\n",
    "        new_group['z_fft_std'].append(z_fft.std())\n",
    "    \n",
    "    new_group = pd.DataFrame(new_group)\n",
    "\n",
    "    return new_group\n",
    "\n",
    "def abs_rfft( series ):\n",
    "    complex_fourier = np.fft.rfft( series )\n",
    "    return np.absolute(complex_fourier)\n",
    "\n",
    "def standardize(df):\n",
    "    \"\"\"\n",
    "    Make the mean of data 0 with standard dev of 1\n",
    "    \"\"\"\n",
    "    return (df - df.mean()) / df.std() \n",
    "\n",
    "\n",
    "# Helper functions for windowing the data\n",
    "def window(width, overlap, max_idx):\n",
    "    \"\"\"\n",
    "    Generates tuples of indices that define a window\n",
    "    of given width and overlap. \n",
    "    \n",
    "    For example:\n",
    "    window(width=10, overlap=0.5, max_length=30)\n",
    "    (0, 10)\n",
    "    (5, 15)\n",
    "    (10, 20)\n",
    "    (15, 25)\n",
    "    Note: it trims the end; i.e. won't return (25, 30)\n",
    "    \"\"\"\n",
    "    start   = 0\n",
    "    if overlap < 0.0 or overlap >= 1.:\n",
    "        raise ValueError(\"overlap needs to be a number between 0 and 1\")\n",
    "    while True:\n",
    "        end = start + width\n",
    "        if end >= max_idx:\n",
    "            return None\n",
    "        yield start, end\n",
    "        start  += max(int((1-overlap)*width), 1)\n",
    "\n",
    "        \n",
    "def window_df(df, width, overlap):\n",
    "    \"\"\"\n",
    "    Applies window to a dataframe\n",
    "    \"\"\"\n",
    "    windows = window(width, overlap, len(df))\n",
    "    for start, end in windows:\n",
    "        yield df[start:end]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['016', '017', '018', '009', '010', '004', '002', '015', '014',\n",
       "       '020', '007', '019', '008', '003', '005', '006', '013', '011',\n",
       "       '001'], dtype='<U3')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data cleanining\n",
    "#pd.read_csv('healthy_subset/004/food.csv').drop([1,4,11]).reset_index(drop=True).to_csv( 'healthy_subset/004/food.csv')\n",
    "#pd.read_csv('healthy_subset/002/food.csv').drop([25,27]).reset_index(drop=True).to_csv( 'healthy_subset/002/food.csv')\n",
    "#pd.read_csv('healthy_subset/007/food.csv').drop([11,15]).reset_index(drop=True).to_csv( 'healthy_subset/007/food.csv')\n",
    "#pd.read_csv('healthy_subset/013/food.csv').drop([5,8,10,11]).reset_index(drop=True).to_csv( 'healthy_subset/013/food.csv')\n",
    "#pd.read_csv('healthy_subset/013/food.csv').drop([9]).reset_index(drop=True).to_csv( 'healthy_subset/013/food.csv')\n",
    "#x = pd.read_csv('healthy_subset/017/glucose.csv')\n",
    "#x.iloc[17,2]=7.0\n",
    "#x.iloc[17,2]\n",
    "#x.to_csv('healthy_subset/017/glucose.csv')\n",
    "#x = pd.read_csv('healthy_subset/014/glucose.csv')\n",
    "#x.iloc[0,3] ='BB' # assumed this value to be bb because the first meal was at 12:20, after another 'BL' measurement\n",
    "#x.iloc[0,3]\n",
    "#x.to_csv('healthy_subset/014/glucose.csv')\n",
    "#x = pd.read_csv('healthy_subset/006/glucose.csv')\n",
    "#pd.read_csv('healthy_subset/006/food.csv')\n",
    "#x.iloc[0,3] ='BB' # assumed this value to be bb because the first meal was at 9:19\n",
    "#x.iloc[1,3] = 'AB' \n",
    "#x.to_csv('healthy_subset/006/glucose.csv')\n",
    "np.array([name for name in os.listdir('healthy_subset')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At subject no  009  time  21:50:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:208: RuntimeWarning: Mean of empty slice.\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-02\n",
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:208: RuntimeWarning: Mean of empty slice.\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-04\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:208: RuntimeWarning: Mean of empty slice.\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-04\n",
      "45\n",
      "gluco date: 2014-10-01\n",
      "76\n",
      "gluco date: 2014-10-03\n",
      "70\n",
      "At subject no  004  time  21:57:00\n",
      "gluco date: 2014-10-02\n",
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:208: RuntimeWarning: Mean of empty slice.\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-01\n",
      "1\n",
      "gluco date: 2014-10-01\n",
      "69\n",
      "gluco date: 2014-10-03\n",
      "47\n",
      "gluco date: 2014-10-04\n",
      "61\n",
      "gluco date: 2014-10-04\n",
      "5\n",
      "At subject no  002  time  22:02:29\n",
      "gluco date: 2014-10-03\n",
      "42\n",
      "gluco date: 2014-10-01\n",
      "45\n",
      "gluco date: 2014-10-04\n",
      "57\n",
      "gluco date: 2014-10-02\n",
      "79\n",
      "gluco date: 2014-10-03\n",
      "37\n",
      "gluco date: 2014-10-01\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:208: RuntimeWarning: Mean of empty slice.\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:208: RuntimeWarning: Mean of empty slice.\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-04\n",
      "14\n",
      "At subject no  007  time  22:08:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-03\n",
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-01\n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-02\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-04\n",
      "81\n",
      "At subject no  008  time  22:16:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-03\n",
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-03\n",
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-01\n",
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-02\n",
      "102\n",
      "At subject no  003  time  22:23:43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluco date: 2014-10-03\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a07e7364f054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Runing this takes more than two hours. Intermediate summaries per individual are therefore separatly, in case the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#algorythm stops, e.g. due to a an error or a n.a. value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_feature_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/diabetes_subset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-083fd3ae7004>\u001b[0m in \u001b[0;36mcreate_feature_table\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    336\u001b[0m                                  \u001b[0msummary_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                                  \u001b[0msubject_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                                  [glucose_record,food_record])\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mextracted_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextracted_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_features_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-083fd3ae7004>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(accel_file_path, summary_file_path, subject_no, diet_params_arr)\u001b[0m\n\u001b[1;32m     97\u001b[0m                                                                 \u001b[0;34m,\u001b[0m \u001b[0mcurrent_day\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                                                 \u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                                                                 , end_time)], axis=1)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mday_features_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubject_no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-083fd3ae7004>\u001b[0m in \u001b[0;36mextract_diet_domain_features\u001b[0;34m(subject_diet_params, date, start_time, end_time)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_10_min_windows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mPGC_score\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg2\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mglucose_day_time_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglucose_time_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglucose_day_time_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglucose_time_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;31m#f1,f2           = food_day_time_array[food_time_index],food_day_time_array[food_time_index+1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "#Runing this takes more than two hours. Intermediate summaries per individual are therefore separatly, in case the\n",
    "#algorythm stops, e.g. due to a an error or a n.a. value. \n",
    "x = create_feature_table('/healthy_subset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of col removed:  0.0 equal to  0 rows\n"
     ]
    }
   ],
   "source": [
    "##the first part creates an overall summary  from the the individuals summary files in case the prior algorithm \n",
    "#was interrupted\n",
    "x.to_csv('overall_summaryV2.0.csv')\n",
    "x = pd.DataFrame()\n",
    "for summary in os.listdir('summaries_folder'):\n",
    "    x = x.append(pd.read_csv('summaries_folder/' + summary))\n",
    "\n",
    "##finally the ranking from above is added as an additional column and rows with invalid values are removed:\n",
    "x['ranking'] = [RANKING_healthy_num[i] for i in  x.subject_id]\n",
    "prior_len = len(x)\n",
    "x = x[~(x.cals==0)] # removing entries where no diet has been captures (@013- 3.10)\n",
    "print('Percent of col removed: ', round((prior_len-len(x))/len(x),2), 'equal to ', prior_len-len(x), 'rows')\n",
    "x.to_csv('overall_summaryV2.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarizing the features to a daily level. Columns need to be indicated to make the choice of features easier,\n",
    "#i.e. to have @column: data as the first index (columns are sorted alphabetically otherwise)\n",
    "x_columns = ['date','breathing_rate_at_activity',\n",
    "       'average_activity_intensity', 'classified_activityLvl',\n",
    "       'classified_activity', 'c_proportion_of_sedentary_behaviors',\n",
    "       'c_active_minutes_in_window', 'c_sedentary_minutes_in_window',\n",
    "       'c_breathing_rate_minus_activityLvl', 'c_average_activity_intensityLvl',\n",
    "       'summary_based_activityLvl', 's_proportion_of_sedentary_behaviors',\n",
    "       's_active_minutes_in_window', 's_sedentary_minutes_in_window',\n",
    "       's_breathing_rate_at_activityLvl', 's_average_activity_intensityLvl',\n",
    "       'average_heart_rate_by_activity_intensity', 'average_heart_rate_day',\n",
    "       'average_heart_rate_filtered', 'average_resting_heart_rate',\n",
    "       'heart_rate_max_min', 'heart_rate_max_min_day', 'sandard_deviation_HR',\n",
    "       'sandard_deviation_HR_day',\n",
    "       'standard_deviation_of_the_interbeat_interval', 'fasting_glucose',\n",
    "       'calories_per_day', 'unbalanced_calories',\n",
    "       'calories_divided_by_mean_activity_level', 'subject_id', 'ranking']\n",
    "x['date'] = [date[0:10] for date in x.Time]\n",
    "sum_sum = pd.DataFrame(columns = x_columns )\n",
    "for _, individual in x.groupby('subject_id'):\n",
    "    for day, individual_day in individual.groupby('date'):\n",
    "        day_summary = individual_day.mean()\n",
    "        day_summary['date']=day\n",
    "        sum_sum = sum_sum.append(day_summary, ignore_index=True)\n",
    "sum_sum.to_csv('day_summary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
